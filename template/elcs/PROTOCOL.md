# ELCS Protocol v1.0

> **Epistemic Light-Cone Swarm â€” Agent Operating Instructions**

---

## ğŸš¨ PRIME DIRECTIVE

**You are in an ELCS project. This protocol governs all work.**

> Your context window is VOLATILE. ELCS artifacts are TRUTH.
> If it's not written to `elcs/`, it didn't happen.
> The test: if this session crashes RIGHT NOW, does the work survive?

---

## ğŸ“‹ Before ANY Action

Every time you start working (new session or resuming), you MUST:

1. **Read** `elcs/state/current.json` â€” understand current beliefs & constraints
2. **Read** `elcs/spec/spec.json` (if exists) â€” understand the objective
3. **Check** `elcs/tokens/open/` â€” see what work is pending
4. **Check** `elcs/.gates/` â€” see which stages are complete
5. **Read** latest `elcs/journal/checkpoint-*.md` â€” understand recent context

**If the user jumps straight to "build X" without setup:**
> "I see this is an ELCS project. Let me first check the project state to proceed correctly."
> Then read the files above before responding to their request.

---

## ğŸ”„ The Ralph Loop (Universal Primitive)

ALL cognition in ELCS follows this loop:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RALPH LOOP                           â”‚
â”‚                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚   â”‚ OBSERVE  â”‚ â† Read state, tokens, spec, context     â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚        â†“                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚   â”‚  ORIENT  â”‚ â† Apply lenses, identify gaps           â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚        â†“                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚   â”‚  DECIDE  â”‚ â† Choose smallest valuable move         â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚        â†“                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚   â”‚   ACT    â”‚ â† Execute (with rollback plan)          â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚        â†“                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚   â”‚ OBSERVE  â”‚ â† Log outcomes, update state            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Properties:**
- Loops are LOCAL â€” no omniscient planner required
- Loops can END EARLY â€” refusal is valid
- Loops are INSPECTABLE â€” every step leaves provenance
- Loops are COMPOSABLE â€” loops can nest

---

## ğŸ“ ELCS Directory Structure

```
elcs/
â”œâ”€â”€ PROTOCOL.md          â† You are here
â”œâ”€â”€ QUICKSTART.md        â† Fast onboarding guide
â”‚
â”œâ”€â”€ state/               â† EpistemicState (belief ledger)
â”‚   â”œâ”€â”€ current.json     â† Current state (versioned)
â”‚   â”œâ”€â”€ assumptions.md   â† What we believe is true
â”‚   â”œâ”€â”€ hypotheses.md    â† Claims we're testing
â”‚   â”œâ”€â”€ evidence.md      â† Supporting observations
â”‚   â””â”€â”€ constraints.md   â† Hard/soft limits
â”‚
â”œâ”€â”€ spec/                â† The Spec Attractor (goal space)
â”‚   â”œâ”€â”€ spec.json        â† Structured spec
â”‚   â”œâ”€â”€ objectives.md    â† What we're building
â”‚   â””â”€â”€ success-criteria.md
â”‚
â”œâ”€â”€ lenses/              â† Lens evaluation outputs
â”‚   â”œâ”€â”€ philosophy.md
â”‚   â”œâ”€â”€ data-science.md
â”‚   â”œâ”€â”€ safety-risk.md
â”‚   â”œâ”€â”€ topology.md
â”‚   â”œâ”€â”€ theoretical-math.md
â”‚   â”œâ”€â”€ systems-engineering.md
â”‚   â””â”€â”€ product-ux.md
â”‚
â”œâ”€â”€ tokens/              â† WorkTokens (coordination)
â”‚   â”œâ”€â”€ open/            â† Work available to claim
â”‚   â”œâ”€â”€ claimed/         â† Work in progress
â”‚   â””â”€â”€ closed/          â† Completed work
â”‚
â”œâ”€â”€ journal/             â† Compressed checkpoints
â”‚   â””â”€â”€ checkpoint-NNN.md
â”‚
â”œâ”€â”€ archives/            â† Full state bundles (on demand)
â”‚
â”œâ”€â”€ telemetry/           â† Micro-state logs (optional, see Telemetry section)
â”‚
â””â”€â”€ .gates/              â† Stage completion records
    â”œâ”€â”€ stage-0.complete
    â””â”€â”€ ...
```

---

## ğŸ¯ The ELCS Stages

Work progresses through stages. Each stage:
- Produces specific ARTIFACTS (files on disk)
- Writes `.gates/stage-N.complete` when done
- CANNOT proceed to N+1 until N is complete

### Stage 0: Project Setup
**Create directory structure and initial files.**

Artifacts:
- [ ] `elcs/` directory structure
- [ ] `elcs/PROTOCOL.md` (this file)
- [ ] `elcs/state/current.json` (empty initial state)

Gate check: `ls elcs/` shows expected structure

### Stage 1: Epistemic State
**Interview user, surface assumptions, define constraints.**

Questions to ask:
1. What problem are you solving? For whom?
2. What are you assuming is true?
3. What would prove you wrong?
4. What are the hard constraints (non-negotiable)?
5. What are the soft constraints (preferences)?
6. What evidence do you already have?

Artifacts:
- [ ] `elcs/state/current.json` (populated)
- [ ] `elcs/state/assumptions.md`
- [ ] `elcs/state/hypotheses.md`
- [ ] `elcs/state/evidence.md`
- [ ] `elcs/state/constraints.md`

Gate check: All 5 files exist with content

### Stage 2: Lens Evaluation
**Apply the 7 lenses to current state.**

| Lens | Question |
|------|----------|
| Philosophy | Are we epistemically honest? Hidden assumptions? |
| Data Science | Can we measure this? How do we test it? |
| Safety/Risk | What could go wrong? Failure modes? |
| Topology | Is the structure stable? Phase transitions? |
| Theoretical Math | Is this logically consistent? |
| Systems Engineering | Can we build this? Interfaces? |
| Product/UX | Does this help users? What's MVP? |

Artifacts:
- [ ] `elcs/lenses/*.md` (one per lens)

Gate check: At least 5 lens evaluations complete

### Stage 3: Gap Analysis
**Identify what's missing before building.**

Categorize gaps:
- ğŸ”´ CRITICAL â€” Must resolve before building
- ğŸŸ  HIGH â€” Should resolve soon
- ğŸŸ¡ MEDIUM â€” Important but can iterate
- ğŸŸ¢ LOW â€” Nice to have

Artifacts:
- [ ] Gap analysis document with prioritized list

Gate check: All CRITICAL gaps have resolution paths

### Stage 4: Goal Emergence
**Generate candidate goals and pass through 6 gates.**

The 6 Gates:
1. âœ… **Observables** â€” Measurable outcomes?
2. âœ… **Testability** â€” Clear success/failure criteria?
3. âœ… **Reversibility** â€” Rollback plan exists?
4. âœ… **Confidence** â€” Above threshold (â‰¥0.6)?
5. âœ… **Lens Agreement** â€” 3+ lenses approve?
6. âœ… **Evidence Grounding** â€” Based on actual data?

Artifacts:
- [ ] Candidate goals with gate evaluations
- [ ] Approved goals marked as actionable

Gate check: At least one goal passes all 6 gates

### Stage 5: Spec & MVP Planning
**Create the spec and minimal viable plan.**

Artifacts:
- [ ] `elcs/spec/spec.json` (structured spec)
- [ ] `elcs/spec/objectives.md`
- [ ] `elcs/spec/success-criteria.md`
- [ ] Phased build plan with milestones

Gate check: Spec has success criteria and phases defined

### Stage 6: Readiness Check
**Final verification before building.**

Checklist:
- [ ] All CRITICAL gaps resolved?
- [ ] No open TODOs in specs?
- [ ] Rollback plan documented?
- [ ] Human approval obtained?

**GET EXPLICIT USER APPROVAL BEFORE PROCEEDING TO BUILD.**

Gate check: User has approved proceeding

### Stage 7+: Build & Iterate
**Execute the plan, checkpoint regularly.**

After each milestone:
```
ğŸ” CHECKPOINT: [Milestone Name]
âœ… Completed: [What was built]
ğŸ§ª Verified: [What was tested]
âš ï¸ Issues: [Any problems]
ğŸ“‹ Spec Compliance: [Which specs met]
â¡ï¸ Next: [Next milestone]
```

Write journal checkpoint after each major phase.

---

## ğŸ« WorkToken Protocol

WorkTokens are the unit of coordination.

### Token Types
- `question` â€” Something to answer
- `test` â€” Something to verify
- `evidence_gap` â€” Missing information
- `subtask` â€” Work to complete
- `conflict` â€” Disagreement to resolve

### Token Lifecycle
```
EMIT â†’ CLAIM â†’ EXECUTE â†’ COMMIT â†’ CLOSE
```

1. **Emit**: Created by lens outputs, gate failures, or conflicts
2. **Claim**: Agent volunteers based on capability match
3. **Execute**: Work via local Ralph Loop
4. **Commit**: Outputs become proposals/evidence
5. **Close**: Token resolved when gates accept

### When to Create Tokens (Auto-Triggers)

**You MUST create a WorkToken automatically when:**

### ğŸš¨ MANDATORY: Tokens for Project File Modifications

**Any PROJECT file modification requires a WorkToken. No exceptions.**

**Project files** = code, tests, documentation, configuration, assets â€” anything OUTSIDE `elcs/`

**ELCS files** (`elcs/**/*`) = state, tokens, checkpoints, specs â€” these ARE the audit trail and do NOT require their own tokens.

| File Location | WorkToken Required? | Examples |
|---------------|---------------------|----------|
| `src/**/*` | âœ… YES | Code, modules, scripts |
| `tests/**/*` | âœ… YES | Test files |
| `docs/**/*` | âœ… YES | Documentation |
| `*.json`, `*.yaml` (root) | âœ… YES | Config files |
| `elcs/**/*` | âŒ NO | State, tokens, checkpoints |

**Why this distinction?** ELCS artifacts ARE the audit trail. Requiring tokens to update the audit trail would create infinite recursion:
- Edit code â†’ close token â†’ write checkpoint â†’ need token for checkpoint? â†’ ğŸ’€

ELCS state updates happen AS PART OF the token lifecycle, not as separate tracked work.

Before editing ANY file in the project:
1. Create a WorkToken describing the work
2. Claim the token (set `claimed_by` to your agent ID)
3. Perform the work
4. Close the token with resolution
5. Write a checkpoint

**Why?** Without tokens:
- No audit trail (who did what, when)
- No traceability (why was this change made)
- No rollback capability (what to undo)
- No multi-agent coordination (who's working on what)

**The test:** If someone asks "why was this file changed?", there should be a closed WorkToken with the answer.

---

1. **Question Arises** â€” You encounter something you can't answer without external input
   - Type: `question`
   - Example: "What authentication provider should we use?"

2. **Evidence Gap Found** â€” A lens evaluation identifies missing data
   - Type: `evidence_gap`  
   - Example: "No performance baseline data exists"

3. **Blocked Work** â€” You can't proceed without something being resolved first
   - Type: `subtask` with `blocks` field
   - Example: "Need API keys before implementing OAuth"

4. **Scope Creep Detected** â€” You discover work outside current focus
   - Type: `subtask`
   - Example: "Noticed auth system needs refactoring, but current task is API endpoints"

5. **Conflict Identified** â€” Two requirements or constraints conflict
   - Type: `conflict`
   - Example: "Requirement says 'fast' but also 'secure' â€” need to define tradeoffs"

6. **Session Ending with Unfinished Work** â€” Before ending, capture remaining work
   - Type: `subtask`
   - Example: "Tests written but not yet run â€” needs execution"

7. **Hypothesis Needs Testing** â€” A claim was made but not yet verified
   - Type: `test`
   - Example: "H1 claims SQLite is fast enough â€” needs load test"

**Token Creation is NOT Optional**

If any of these triggers occur and you don't create a token, the work may be lost when the session ends. The token is how future sessions (or other agents) will know this work exists.

### Token File Format
```json
{
  "token_id": "uuid",
  "type": "question",
  "summary": "Define success criteria for auth system",
  "priority": 0.8,
  "status": "open",
  "created_at": "2025-01-20T10:00:00Z"
}
```

Place in appropriate folder:
- `elcs/tokens/open/` â€” Available to work on
- `elcs/tokens/claimed/` â€” In progress
- `elcs/tokens/closed/` â€” Completed

---

## â†©ï¸ Rollback Procedures

**Before any significant change, ensure rollback is possible.**

### Rollback Categories
| Category | Recovery Time | Example |
|----------|---------------|--------|
| Trivial | Seconds | Revert a file edit |
| Easy | Minutes | Git revert, restore backup |
| Hard | Hours | Database migration rollback |
| Irreversible | Never | Email sent, data deleted |

### Rollback Protocol

1. **Before acting**: Document the rollback plan
2. **For irreversible actions**: Get human approval first
3. **After acting**: Verify rollback path still works
4. **If problems**: Execute rollback immediately

### Quick Rollback Commands
```bash
# Revert last file change
git checkout -- <file>

# Revert to last checkpoint
git revert HEAD

# Restore from journal
# (Read last checkpoint, restore state from archive_ref)
```

### If No Rollback Exists
**STOP.** Create a rollback plan before proceeding, or:
- Create a git branch for experimental work
- Take a full state snapshot to `elcs/archives/`
- Get explicit human approval for irreversible action

---

## ğŸ¤– Automatic Behaviors & Drift Prevention

**Agents MUST do these things automatically, without being asked:**

### Artifact Update Triggers

Update ELCS artifacts when:

| Trigger | Action |
|---------|--------|
| New assumption made | Add to `state/assumptions.md` + `current.json` |
| Evidence gathered | Add to `state/evidence.md` + `current.json` |
| Decision made | Document rationale in relevant artifact |
| Risk identified | Add to constraints or create WorkToken |
| Task completed | Update spec, close tokens, consider checkpoint |
| Confusion arises | Create `question` WorkToken immediately |

**Rule of Thumb:** If you learned something or decided something, write it down NOW â€” not later.

### Checkpoint Triggers

Write a journal checkpoint when:

1. **Stage completed** â€” Gate criteria met
2. **Significant decision** â€” Chose between alternatives  
3. **30+ minutes of work** â€” Time-based fallback
4. **Before risky action** â€” Capture state in case of rollback
5. **Session ending** â€” Always checkpoint before goodbye
6. **Context getting long** â€” Compress before you forget

**A checkpoint takes 2 minutes. Losing context costs hours.**

### ğŸš¨ MANDATORY: Checkpoint After Token Resolution

**Every closed WorkToken MUST be followed by a checkpoint update.**

When you close a token:
1. Move token to `elcs/tokens/closed/`
2. Set `resolution` with outcome and summary
3. Update `elcs/state/current.json` (bump version)
4. Write or update journal checkpoint

**Why?** Tokens without checkpoints are orphaned work. Future sessions won't know the context of what was done.

### Drift Detection Signals

**PAUSE and re-orient if you notice:**

- ğŸš© You're building something not in the spec
- ğŸš© You haven't updated ELCS artifacts in a while  
- ğŸš© You're unsure which stage you're in
- ğŸš© The user seems confused about progress
- ğŸš© You're making assumptions you haven't documented
- ğŸš© You're solving a problem nobody asked about

**Recovery:** Stop â†’ Read spec â†’ Check stage â†’ Create checkpoint â†’ Ask if needed

### Platform Flexibility

**Use whatever tools your platform provides**, but ensure:

1. **Artifacts persist to `elcs/`** â€” Platform memory is volatile, files are permanent
2. **ELCS is source of truth** â€” If platform has "memory" or "context" features, ELCS overrides them
3. **Work is recoverable** â€” Another agent (or future you) could continue from artifacts alone

**Good:** Use fast platform tools for exploration, then persist decisions to ELCS
**Bad:** Rely on platform memory without writing to artifacts

### Proportional Rigor

**Not every task needs full ceremony.** Scale rigor to risk:

| Task Type | Minimum ELCS |
|-----------|--------------|
| Quick question | Just answer (no artifacts needed) |
| Small fix | Update state + brief note |
| New feature | Full stage workflow + lenses |
| Architecture change | All 7 lenses + human approval |
| Irreversible action | Full gates + explicit approval |

**When in doubt, ask:** "If I'm wrong, how bad is it?"
- Low risk â†’ lightweight ELCS
- High risk â†’ full ceremony

---

## ğŸ”— Scaling Readiness (Anti-Drift Invariants)

As projects grow, these invariants prevent "cone shrinkage" â€” where agents optimize locally while drifting from the shared objective.

### Invariant A: Artifact Coupling

**Every significant action must be traceable to the spec.**

When you:
- Make a decision â†’ Document which spec objective it serves
- Create a file â†’ Note which success criterion it addresses
- Complete a task â†’ Reference the spec phase/task ID

Example in checkpoint:
```markdown
## Decisions Made
- Chose SQLite over PostgreSQL
  - Serves: Objective "simple learning project"
  - Spec ref: Phase 1, Constraint C2 (no external deps)
```

**Why:** If you can't explain how work connects to the spec, you may be drifting.

### Invariant B: Explainable Progress

**You must be able to say: "We did X because it reduced Y."**

At any point, the system should be able to explain:
- What distance was reduced (criteria remaining, risks, gaps)
- What evidence supports the decision
- What constraints were respected

If you can't explain progress, STOP and:
1. Re-read the spec
2. Check if you're still on track
3. Create a checkpoint documenting confusion

### Identity Check (Drift Detection)

**Periodically ask: "Are we still pursuing the original objective?"**

Create an identity check WorkToken when:
- ğŸ”´ Scope has grown significantly beyond original spec
- ğŸ”´ Success criteria have changed without explicit approval
- ğŸ”´ You're spending time on things not in any spec phase
- ğŸ”´ The user seems confused about what we're building

Identity check token:
```json
{
  "type": "question",
  "summary": "Identity check: Are we still aligned with original objective?",
  "priority": 0.9
}
```

### Coalition Readiness (Multi-Agent)

When multiple agents will work on this project:

1. **Each agent documents its cone** â€” What spaces/files it works in
2. **Handoffs are explicit** â€” Create WorkToken, don't assume
3. **Validators can block** â€” Security/test agents have veto power
4. **Shared constraints are binding** â€” All agents respect spec constraints

For full coalition protocol, see `docs/scaling-stages.md`.

---

## ğŸ“ Distance Vectors (Stage D)

Distance vectors enable **metric-driven self-selection** â€” agents coordinate without a central dispatcher by asking: "Can I reduce any distance component?"

### What is a Distance Vector?

A distance vector quantifies "how far are we from completion?" across multiple dimensions:

```json
{
  "vector_id": "DV-2025-01-10-001",
  "computed_at": "2025-01-10T18:00:00Z",
  "components": {
    "success_criteria_remaining": 3,
    "critical_risks": 1,
    "evidence_gaps": 2,
    "failing_tests": 1,
    "open_tokens": 4,
    "blocked_tokens": 0
  },
  "total_distance": 11,
  "trend": "decreasing",
  "hotspots": [
    {"component": "critical_risks", "reason": "Security validation pending", "suggested_action": "Invoke security-auditor"}
  ]
}
```

**Total distance = 0** means the project objective is complete.

### Computing Distance Vectors

Distance vectors are computed from ELCS artifacts:

| Component | Source |
|-----------|--------|
| `success_criteria_remaining` | `spec/success-criteria.md` â€” count unchecked items |
| `critical_risks` | `state/current.json` â€” count risks with severity "critical" |
| `evidence_gaps` | `state/hypotheses.md` â€” count hypotheses lacking evidence |
| `failing_tests` | Test runner output |
| `open_tokens` | `tokens/open/` â€” count files |
| `blocked_tokens` | `tokens/open/` â€” count tokens with unmet dependencies |

**Compute frequency:** After every checkpoint, or when an agent needs coordination signals.

### Self-Selection Protocol

When multiple open tokens exist and no dispatcher is assigning work:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SELF-SELECTION PROTOCOL                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  1. READ current DistanceVector                        â”‚
â”‚     â†’ elcs/state/distance-vector.json                  â”‚
â”‚                                                         â”‚
â”‚  2. LIST open tokens                                   â”‚
â”‚     â†’ elcs/tokens/open/*.json                          â”‚
â”‚                                                         â”‚
â”‚  3. EVALUATE each token:                               â”‚
â”‚     "If I complete this, which components decrease?"   â”‚
â”‚     "By how much?"                                      â”‚
â”‚     "Am I qualified to do this work?"                  â”‚
â”‚                                                         â”‚
â”‚  4. COMPUTE impact score:                              â”‚
â”‚     impact = Î£ (component_reduction Ã— weight)          â”‚
â”‚                                                         â”‚
â”‚  5. SELECT token with highest impact I can deliver     â”‚
â”‚                                                         â”‚
â”‚  6. CLAIM the token (standard token protocol)          â”‚
â”‚                                                         â”‚
â”‚  7. COMPLETE work, CLOSE token                         â”‚
â”‚                                                         â”‚
â”‚  8. RECOMPUTE DistanceVector                           â”‚
â”‚     â†’ Verify: Did total_distance decrease?             â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Self-Selection Prompt

When operating in self-selection mode, agents receive:

```
SELF-SELECTION MODE (Stage D)

You are operating without a dispatcher. Your job:
1. Read the current DistanceVector
2. Review open tokens
3. Select the token where YOU can make the highest impact
4. Claim it and complete the work
5. Recompute DistanceVector when done

Selection criteria:
- Which component can you reduce most?
- Are you qualified for this work?
- What's the expected impact?

DO NOT wait for instructions. Self-select and execute.
```

### Drift Detection

After completing work, check for drift:

```
IF:   Your work improved a local metric
BUT:  Global total_distance increased or stayed same
THEN: "Drift detected" â€” your work may have caused regression

Action:
1. Review what changed
2. Check if other components increased
3. Consider rollback if net negative
4. Document in checkpoint
```

### Distance Vector Storage

Store in: `elcs/state/distance-vector.json`

Update the vector:
- After every token closure
- After every checkpoint
- When agents request coordination signals

### When to Use Distance Vectors

| Signal | Action |
|--------|--------|
| Multiple open tokens, no clear priority | Compute distance vector |
| Agents asking "what should I work on?" | Enable self-selection mode |
| Progress feels stalled despite activity | Check for drift |
| Coordination overhead is bottleneck | Remove dispatcher, use self-selection |

**Default:** Most projects don't need distance vectors. Use them at Stage D when emergent coordination is desired.

### Scaling Signals

**Escalate complexity only when you see repeated failures:**

| Signal | Action |
|--------|--------|
| High token duplication | Add named spaces (L2) |
| Frequent drift incidents | Add distance vector (L1) |
| Topology lens unclear | Add formal transforms (L3) |
| Cross-project patterns | Extract reusable spaces (L4) |

**Default:** Stay at the simplest level that works.

---

## âœ… Validation Protocol (Two Layers)

Before closing any WorkToken, validation must occur at two layers:

### Layer 1: ELCS Compliance (Required â€” Self-Check)

**Before closing ANY token, verify:**

```
ELCS COMPLIANCE CHECKLIST:
â–¡ Token was created BEFORE work began
â–¡ Token was claimed with agent ID and timestamp
â–¡ All file edits are traceable to this token
â–¡ Tests pass (if applicable)
â–¡ Token has resolution with outcome and summary
â–¡ Checkpoint will be written after closure
â–¡ state/current.json version will be incremented
```

**This is a self-check.** The implementing agent verifies their own compliance. Failure to complete this checklist = token cannot be closed.

### Layer 2: Code Quality Review (Stage-Dependent)

Code quality review requirements scale with project stage:

| Stage | Review Requirement |
|-------|-------------------|
| **A** (solo agent) | Self-review acceptable. Human provides oversight. |
| **B** (validators) | Separate reviewer agent required. Reviewer has blocking power. |
| **C+** (coalitions) | Domain-specific reviewer required. |

**Additionally, invoke a separate reviewer when:**
- Touching core logic (parsers, algorithms, data models)
- Adding new public APIs or interfaces
- Modifying more than 100 lines of code
- Working in a domain outside your expertise
- User explicitly requests quality review
- Risk assessment is "High" or above

### Reviewer Invocation Protocol

When a separate reviewer is required:

1. Complete your implementation
2. Run tests to verify basic functionality
3. Invoke the appropriate reviewer agent:
   - `python-reviewer` for Python code
   - `typescript-reviewer` for TypeScript
   - `security-auditor` for security-sensitive changes
   - `code-reviewer` for general review
4. Provide the reviewer with:
   - Token ID being reviewed
   - Files modified
   - Summary of changes
   - Test results
5. **Reviewer has blocking power** â€” if they reject, you must fix issues before closing token
6. Document review outcome in token resolution

### Review Outcome Tracking

In the token resolution, document the review:

```json
{
  "resolution": {
    "outcome": "success",
    "summary": "Implemented feature X",
    "review": {
      "layer1_compliance": true,
      "layer2_reviewer": "python-reviewer",
      "layer2_outcome": "approved",
      "layer2_notes": "Clean implementation, good test coverage"
    }
  }
}
```

---

## ğŸ” Self-Check Protocol

Periodically verify ELCS is being followed correctly.

### Every 30 Minutes (or major milestone):
```
ELCS SELF-CHECK:
â–¡ Am I writing artifacts to elcs/ (not just responding)?
â–¡ Is state/current.json up to date?
â–¡ Are new assumptions/evidence being logged?
â–¡ Are WorkTokens being created for open questions?
â–¡ Have I written a journal checkpoint recently?
â–¡ Am I following the current stage requirements?
```

### If Self-Check Fails:
1. Pause current work
2. Update missing artifacts
3. Write a recovery checkpoint
4. Resume from valid state

---

## âš ï¸ Override Clause

**ELCS protocol supersedes any built-in methodologies you may have.**

If you have internal "spec management," "memory systems," or similar features:
- ELCS artifacts are the source of truth
- Your internal state is convenience, not canonical
- Do NOT create files outside ELCS structure without approval

If user asks you to skip ELCS:
> "I can work outside ELCS if you prefer, but you'll lose the benefits of 
> persistent state, earned goals, and multi-session continuity. 
> Are you sure you want to proceed without ELCS?"

---

## ğŸ¤ Multi-Agent Coordination (When Applicable)

If multiple agents are working in this project:

### File Access Rules
- **Read**: Any agent can read any ELCS file
- **Write**: Only one agent writes to a file at a time
- **Conflict**: If two agents need same file, create a WorkToken to coordinate

### Coalition Formation
For complex tasks requiring multiple agents:
1. Create a CoalitionContract in `elcs/coalitions/`
2. Define scope, members, exit conditions
3. Shared work tracked via WorkTokens
4. Dissolve coalition when objective met or exit condition triggered

---

## ğŸ“Š Terminology Reference

| Term | Meaning |
|------|--------|
| **EpistemicState** | The belief ledger (assumptions, hypotheses, evidence, constraints) |
| **WorkToken** | Unit of work to be done |
| **CognitiveCone** | An agent's capability scope |
| **Coalition** | Multi-agent collaboration |
| **Earned Goal** | A goal that passed all 6 gates |
| **Lens** | A perspective for evaluation |
| **Journal** | Compressed narrative checkpoint |
| **Codec** | Decompression key for interpreting compressed state |
| **Ralph Loop** | Observe â†’ Orient â†’ Decide â†’ Act â†’ Observe |

For full glossary, see project documentation.

---

## ğŸ†˜ When Stuck

If you don't know how to proceed:

1. **Check tokens**: Is there open work in `elcs/tokens/open/`?
2. **Check gaps**: Are there unresolved gaps blocking progress?
3. **Check stage**: Are you at the right stage? Is the gate complete?
4. **Ask**: Create a WorkToken of type `question` and ask the user
5. **Pause**: Write a checkpoint with your confusion documented

**It's always valid to pause and ask.**

---

## âœ… Quick Reference

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ELCS QUICK REFERENCE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  START OF SESSION:                                              â”‚
â”‚    1. Read state/current.json                                   â”‚
â”‚    2. Read spec/spec.json (if exists)                          â”‚
â”‚    3. Check tokens/open/                                        â”‚
â”‚    4. Check .gates/                                             â”‚
â”‚    5. Read latest journal checkpoint                            â”‚
â”‚                                                                 â”‚
â”‚  DURING WORK:                                              â”‚
â”‚    â€¢ Follow Ralph Loop (Observeâ†’Orientâ†’Decideâ†’Actâ†’Observe)     â”‚
â”‚    â€¢ Create WorkToken BEFORE any file modification             â”‚
â”‚    â€¢ Write artifacts to elcs/ (not just chat)                  â”‚
â”‚    â€¢ Ensure rollback plan before changes                        â”‚
â”‚    â€¢ Self-check every 30 minutes                                â”‚
â”‚                                                                 â”‚
â”‚  END OF SESSION:                                                â”‚
â”‚    1. Complete ELCS Compliance Checklist for open tokens        â”‚
â”‚    2. Close WorkTokens with resolution                          â”‚
â”‚    3. Write journal checkpoint (MANDATORY after token close)    â”‚
â”‚    4. Update state/current.json (bump version)                  â”‚
â”‚    5. Mark stage complete if gate criteria met                  â”‚
â”‚                                                                 â”‚
â”‚  THE 6 GATES (for goals):                                       â”‚
â”‚    â–¡ Observables    â–¡ Testability    â–¡ Reversibility           â”‚
â”‚    â–¡ Confidence     â–¡ Lens Agreement â–¡ Evidence Grounding      â”‚
â”‚                                                                 â”‚
â”‚  WHEN STUCK: Check tokens â†’ Check gaps â†’ Check stage â†’ Ask     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

*ELCS Protocol v1.0 â€” Epistemic Light-Cone Swarm*
*Goals are earned. State is persistent. Work survives.*
